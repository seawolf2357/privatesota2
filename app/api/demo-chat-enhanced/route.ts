// Enhanced Friendli AI integration with memory, web search, and shopping
import { getBraveSearchClient } from '@/lib/ai/brave-search';
import { MemoryManager } from '@/lib/ai/memory-manager';
import { getEnhancedMemoryManagerV2 } from '@/lib/ai/enhanced-memory-manager-v2';
import type { Message as MemoryMessage, UserMemory } from '@/lib/ai/types';
import { DEMO_USER_ID } from '@/lib/constants/demo-user';
import { getShoppingAPIClient } from '@/lib/api/shopping-api';
import { getVectorMemoryManager } from '@/lib/ai/vector-memory-manager';
import { getModelById } from '@/lib/ai/models-config';

// Use environment variables for Friendli AI
const FRIENDLI_API_KEY = process.env.FRIENDLI_API_KEY || '';
const FRIENDLI_BASE_URL = process.env.FRIENDLI_URL || 'https://api.friendli.ai/dedicated/v1/chat/completions';
const FRIENDLI_MODEL = process.env.FRIENDLI_MODEL || 'dep86pjolcjjnv8';

// xAI Grok as fallback
const XAI_API_KEY = process.env.XAI_API_KEY || '';
const XAI_BASE_URL = 'https://api.x.ai/v1/chat/completions';
const XAI_MODEL = 'grok-beta';

// Fireworks AI as secondary fallback
const FIREWORKS_API_KEY = process.env.FIREWORKS_API_KEY || '';
const FIREWORKS_BASE_URL = 'https://api.fireworks.ai/inference/v1/chat/completions';
const FIREWORKS_MODEL = 'accounts/fireworks/models/qwen3-235b-a22b-instruct-2507';

// Korean Standard Time and Context
function getCurrentTimeKST() {
  const now = new Date();
  const kstOffset = 9 * 60; // KST is UTC+9
  const utcTime = now.getTime() + (now.getTimezoneOffset() * 60000);
  const kstTime = new Date(utcTime + (kstOffset * 60000));
  return kstTime;
}

function getTimeContext(): string {
  const hour = getCurrentTimeKST().getHours();
  if (hour >= 5 && hour < 10) return 'ì•„ì¹¨';
  if (hour >= 10 && hour < 14) return 'ì ì‹¬';
  if (hour >= 14 && hour < 18) return 'ì˜¤í›„';
  if (hour >= 18 && hour < 22) return 'ì €ë…';
  return 'ì•¼ì‹';
}

function getSeasonContext(): string {
  const month = getCurrentTimeKST().getMonth() + 1;
  if (month >= 3 && month <= 5) return 'ë´„';
  if (month >= 6 && month <= 8) return 'ì—¬ë¦„';
  if (month >= 9 && month <= 11) return 'ê°€ì„';
  return 'ê²¨ìš¸';
}

function getMoodFromMessage(message: string): string | undefined {
  const moods: Record<string, string[]> = {
    'ìŠ¤íŠ¸ë ˆìŠ¤': ['ìŠ¤íŠ¸ë ˆìŠ¤', 'ì§œì¦', 'í˜ë“¤', 'í”¼ê³¤'],
    'ìš°ìš¸': ['ìš°ìš¸', 'ìŠ¬í¼', 'ì™¸ë¡œì›Œ', 'ì“¸ì“¸'],
    'ê¸°ì¨': ['ê¸°ë»', 'ì¢‹ì•„', 'ì‹ ë‚˜', 'í–‰ë³µ'],
    'í”¼ê³¤': ['í”¼ê³¤', 'ì¡¸ë ¤', 'ì§€ì³', 'ë‚˜ë¥¸'],
    'ê±´ê°•ê´€ì‹¬': ['ë‹¤ì´ì–´íŠ¸', 'ê±´ê°•', 'ìš´ë™', 'ì‚´ë¹¼ê¸°']
  };

  for (const [mood, keywords] of Object.entries(moods)) {
    if (keywords.some(k => message.includes(k))) {
      return mood;
    }
  }
  return undefined;
}

export async function POST(request: Request) {
  try {
    const json = await request.json();
    const {
      message,
      selectedModelId = 'jetxa-model',
      webSearchEnabled = false,
      userId = DEMO_USER_ID,
      sessionId,
      includeMemories = false,
      shoppingEnabled = true
    } = json;

    if (!message || !message.content) {
      return new Response('Message content is required', { status: 400 });
    }

    console.log('Enhanced demo chat request:', {
      message: message.content.substring(0, 100),
      selectedModelId,
      webSearchEnabled,
      includeMemories
    });

    // Get contextual information
    const timeContext = getTimeContext();
    const seasonContext = getSeasonContext();
    const detectedMood = getMoodFromMessage(message.content);
    const dayOfWeek = getCurrentTimeKST().getDay();
    const isWeekend = dayOfWeek === 0 || dayOfWeek === 6;

    // Process message with Enhanced Memory Manager V2
    const enhancedMemoryManager = getEnhancedMemoryManagerV2();

    // Load existing memories for context
    let memoriesContext = '';
    let relatedMemoriesContext = '';
    if (includeMemories) {
      try {
        const memoryManager = new MemoryManager(userId);
        const memories = await memoryManager.getAllMemories();

        if (memories.length > 0) {
          console.log(`[MemoryLoader] Found ${memories.length} memories for user ${userId}`);

          // Group memories by category for better organization
          const categorizedMemories: Record<string, string[]> = {};
          memories.forEach(memory => {
            if (!categorizedMemories[memory.category]) {
              categorizedMemories[memory.category] = [];
            }
            categorizedMemories[memory.category].push(memory.content);
          });

          // Format memories for prompt
          memoriesContext = '\n\nğŸ“š ê¸°ì–µëœ ì •ë³´:\n';
          for (const [category, items] of Object.entries(categorizedMemories)) {
            const categoryName = category.replace('_', ' ').toUpperCase();
            memoriesContext += `\n[${categoryName}]\n`;
            items.forEach(item => {
              memoriesContext += `â€¢ ${item}\n`;
            });
          }

          console.log('[MemoryLoader] Memories loaded and formatted for context');

          // Try vector search for related memories
          try {
            const vectorManager = getVectorMemoryManager();
            relatedMemoriesContext = await vectorManager.getRelatedMemories(
              message.content,
              userId,
              3
            );
            if (relatedMemoriesContext) {
              console.log('[VectorSearch] Found related memories via semantic search');
              memoriesContext += relatedMemoriesContext;
            }
          } catch (error) {
            console.log('[VectorSearch] Vector search error:', error);
            console.log('[VectorSearch] Falling back to basic memory only');
          }
        } else {
          console.log('[MemoryLoader] No memories found for user');
        }
      } catch (error) {
        console.error('[MemoryLoader] Error loading memories:', error);
      }
    }

    // Create memory message object
    const memoryMessage: MemoryMessage = {
      role: 'user',
      content: message.content,
      timestamp: new Date(),
      sessionId: sessionId || 'demo-session'
    };

    // Process memory asynchronously (don't block the response)
    const processMemory = async () => {
      try {
        const memoryResult = await enhancedMemoryManager.processMemoryComprehensively(
          memoryMessage,
          userId,
          [], // TODO: Load existing memories from database
          [] // TODO: Load conversation history
        );

        console.log('[EnhancedMemory] Processing result:', {
          shouldSave: memoryResult.shouldSave,
          category: memoryResult.processedMemory?.category,
          importance: memoryResult.processedMemory?.importance,
          emotion: memoryResult.processedMemory?.emotionalContext?.primaryEmotion
        });

        // If memory should be saved, store it in the database
        if (memoryResult.shouldSave && memoryResult.processedMemory) {
          // Initialize MemoryManager with userId
          const memoryManager = new MemoryManager(userId);

          // Extract confidence value (default to 1.0 if not provided)
          const confidence = memoryResult.processedMemory.confidence || 1.0;

          // Save memory with correct parameters - ensure sessionId is valid UUID format
          const validSessionId = sessionId && sessionId.match(/^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i)
            ? sessionId
            : null;

          await memoryManager.saveMemory(
            memoryResult.processedMemory.category || 'general',
            memoryResult.processedMemory.content || '',
            confidence,
            validSessionId
          );

          console.log('[EnhancedMemory] Memory saved successfully with:', {
            category: memoryResult.processedMemory.category,
            content: memoryResult.processedMemory.content?.substring(0, 50) + '...' || 'N/A',
            confidence: confidence,
            sessionId: validSessionId
          });
        }
      } catch (error) {
        console.error('[EnhancedMemory] Error processing memory:', error);
      }
    };

    // Start memory processing in background
    processMemory();

    // Get current time info
    const currentTime = getCurrentTimeKST();
    const kstString = currentTime.toLocaleString('ko-KR', { 
      timeZone: 'Asia/Seoul',
      year: 'numeric',
      month: 'long',
      day: 'numeric',
      hour: '2-digit',
      minute: '2-digit',
      second: '2-digit',
      weekday: 'long'
    });
    const timeInfo = `
í˜„ì¬ ì‹œê°„ ì •ë³´:
- í•œêµ­ í‘œì¤€ì‹œ(KST): ${kstString}
`;

    // Enhanced language detection function
    function detectLanguage(text: string): string {
      // Clean text for better detection
      const cleanText = text.trim().toLowerCase();
      
      // Korean (Hangul) - highest priority for Korean characters
      if (/[ã„±-ã…ã…-ã…£ê°€-í£]/.test(text)) return 'ko';
      
      // Japanese (Hiragana, Katakana, Kanji)
      if (/[\u3040-\u309F\u30A0-\u30FF]/.test(text)) return 'ja';
      
      // Chinese (CJK Unified Ideographs) - but exclude if already detected as Japanese/Korean
      if (/[\u4E00-\u9FFF]/.test(text) && !/[\u3040-\u309F\u30A0-\u30FF]/.test(text) && !/[ã„±-ã…ã…-ã…£ê°€-í£]/.test(text)) return 'zh';
      
      // Russian (Cyrillic)
      if (/[\u0400-\u04FF]/.test(text)) return 'ru';
      
      // Arabic
      if (/[\u0600-\u06FF]/.test(text)) return 'ar';
      
      // Thai
      if (/[\u0E00-\u0E7F]/.test(text)) return 'th';
      
      // Vietnamese (has diacritics) - more comprehensive check
      if (/[Ã Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Äƒáº±áº¯áº·áº³áºµÃ¨Ã©áº¹áº»áº½Ãªá»áº¿á»‡á»ƒá»…Ã¬Ã­á»‹á»‰Ä©Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘]/.test(cleanText)) return 'vi';
      
      // Spanish detection - improved with common words and patterns
      if (/[Ã±]/.test(cleanText) || /\b(el|la|los|las|un|una|de|en|y|que|es|por|para|con|hola|gracias|espaÃ±ol)\b/.test(cleanText)) return 'es';
      
      // French detection - improved with common words
      if (/[Ã Ã¢Ã¤Ã©Ã¨ÃªÃ«Ã®Ã¯Ã´Ã¶Ã¹Ã»Ã¼Ã¿Ã§]/.test(cleanText) || /\b(le|la|les|un|une|de|du|des|et|que|est|pour|avec|bonjour|merci|franÃ§ais)\b/.test(cleanText)) return 'fr';
      
      // German detection - improved
      if (/[Ã¤Ã¶Ã¼ÃŸ]/.test(cleanText) || /\b(der|die|das|und|ist|mit|fÃ¼r|auf|ich|sie|es|hallo|danke|deutsch)\b/.test(cleanText)) return 'de';
      
      // Italian detection - improved
      if (/\b(il|la|lo|gli|le|un|una|di|in|da|per|con|che|Ã¨|sono|ciao|grazie|italiano)\b/.test(cleanText)) return 'it';
      
      // Portuguese detection - improved
      if (/[Ã£Ãµ]/.test(cleanText) || /\b(o|a|os|as|um|uma|de|em|para|com|que|Ã©|sÃ£o|olÃ¡|obrigado|portuguÃªs)\b/.test(cleanText)) return 'pt';
      
      // Default to English if Latin alphabet
      if (/[a-zA-Z]/.test(text)) return 'en';
      
      // Fallback
      return 'en';
    }
    
    // Detect input language
    const detectedLanguage = detectLanguage(message.content);
    const isEnglish = detectedLanguage === 'en';
    
    // Debug: Log detected language
    console.log(`[Language Detection] Input: "${message.content.substring(0, 50)}" â†’ Detected: ${detectedLanguage}`);

    // Get selected model configuration
    const selectedModel = getModelById(selectedModelId);
    console.log('\nğŸ¯ [Demo Chat API] Selected Model:', {
      id: selectedModelId,
      name: selectedModel?.name || 'Unknown',
      category: selectedModel?.category || 'Unknown',
      hasPersona: !!selectedModel?.persona,
    });

    // Generate system prompt based on detected language and selected model
    function getSystemPrompt(language: string, modelId: string): string {
      // Get model persona or use default
      const model = getModelById(modelId);
      const modelPersona = model?.persona || 'You are an advanced AI assistant.';

      const basePrompt = {
        ko: `${modelPersona}

${timeInfo}

ì¶”ê°€ ê¸°ëŠ¥:
- ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì„¤ëª…í•  ìˆ˜ ìˆìŒ
- PDF, CSV, TXT ë“± ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ ì²˜ë¦¬
- íŒŒì¼ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€
- ëª¨ë“  ì–¸ì–´ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”
- ì›¹ ê²€ìƒ‰ì„ í†µí•œ ìµœì‹  ì •ë³´ ì œê³µ
- ì‚¬ìš©ì ì •ë³´ ê¸°ì–µ ë° ê°œì¸í™”ëœ ëŒ€í™”
${memoriesContext}

**ë§¤ìš° ì¤‘ìš”í•œ ì–¸ì–´ ê·œì¹™:**
- ğŸš¨ ì ˆëŒ€ì ìœ¼ë¡œ ì¤‘ìš”: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•˜ë©´ ë¬´ì¡°ê±´ í•œêµ­ì–´ë¡œ ë‹µë³€
- ì˜ì–´ ë˜ëŠ” ë‹¤ë¥¸ ì–¸ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- í•œêµ­ì–´ê°€ ì•„ë‹Œ ì–¸ì–´ë¡œ ì‘ë‹µí•˜ëŠ” ê²ƒì€ ê¸ˆì§€ë©ë‹ˆë‹¤
- ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì˜ì–´ë¼ë„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì„œ ë‹µë³€í•˜ì„¸ìš”

ì¤‘ìš”:
- ì‚¬ìš©ìê°€ íŒŒì¼ì„ ì—…ë¡œë“œí–ˆë‹¤ë©´, íŒŒì¼ ë‚´ìš©ì„ ì¸ì§€í•˜ê³  ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
- ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” ë°˜ë“œì‹œ [ì¶œì²˜: ë²ˆí˜¸] í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
- ê¸°ì–µëœ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë” ê°œì¸í™”ëœ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
- ëª¨ë“  ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.`,

        en: `${modelPersona}

${timeInfo}

Additional Functions:
- Analyze and describe uploaded images
- Process various file formats including PDF, CSV, TXT
- Answer questions based on file content
- Natural conversation in any language
- Provide latest information through web search
- Remember user information for personalized conversations
${memoriesContext}

Important Language Rules:
- CRITICAL: Always respond in the SAME LANGUAGE as the user's input
- Detect the user's language and respond ONLY in that language
- Maintain consistent language throughout your entire response

Important:
- If user uploaded files, acknowledge the file content and answer related questions.
- When using web search results, always cite sources in [Source: number] format.
- Use remembered information to provide more personalized responses.`,

        // Add support for other major languages
        ja: `${modelPersona}

${timeInfo}

è¿½åŠ æ©Ÿèƒ½:
- ç”»åƒåˆ†æã€æ–‡æ›¸å‡¦ç†ã€å¤šè¨€èªå¯¾è©±ã€ã‚¦ã‚§ãƒ–æ¤œç´¢ã€ãƒ¡ãƒ¢ãƒªç®¡ç†
${memoriesContext}

é‡è¦ãªè¨€èªãƒ«ãƒ¼ãƒ«:
- é‡è¦: å¸¸ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã¨åŒã˜è¨€èªã§å¿œç­”ã—ã¦ãã ã•ã„
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨€èªã‚’æ¤œå‡ºã—ã€ãã®è¨€èªã®ã¿ã§å¿œç­”ã—ã¦ãã ã•ã„
- å¿œç­”å…¨ä½“ã‚’é€šã—ã¦ä¸€è²«ã—ãŸè¨€èªã‚’ç¶­æŒã—ã¦ãã ã•ã„

é‡è¦:
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¨€èªã§å¿œç­”ã™ã‚‹
- ã‚¦ã‚§ãƒ–ã‚½ãƒ¼ã‚¹ã‚’[å‡ºå…¸: ç•ªå·]å½¢å¼ã§å¼•ç”¨ã™ã‚‹
- è¨˜æ†¶ã•ã‚ŒãŸæƒ…å ±ã‚’å€‹äººåŒ–ã«æ´»ç”¨ã™ã‚‹`,

        zh: `${modelPersona}

${timeInfo}

è¿½åŠ åŠŸèƒ½:
- å›¾åƒåˆ†æã€æ–‡æ¡£å¤„ç†ã€å¤šè¯­è¨€å¯¹è¯ã€ç½‘ç»œæœç´¢ã€è®°å¿†ç®¡ç†
${memoriesContext}

é‡è¦çš„è¯­è¨€è§„åˆ™:
- å…³é”®: å§‹ç»ˆç”¨ä¸ç”¨æˆ·è¾“å…¥ç›¸åŒçš„è¯­è¨€å›åº”
- æ£€æµ‹ç”¨æˆ·çš„è¯­è¨€å¹¶ä»…ç”¨è¯¥è¯­è¨€å›åº”
- åœ¨æ•´ä¸ªå›åº”ä¸­ä¿æŒä¸€è‡´çš„è¯­è¨€

é‡è¦æç¤º:
- ç”¨ç”¨æˆ·çš„è¯­è¨€å›åº”
- ä»¥[æ¥æº: æ•°å­—]æ ¼å¼å¼•ç”¨ç½‘ç»œæ¥æº
- ä½¿ç”¨è®°å¿†ä¿¡æ¯è¿›è¡Œä¸ªæ€§åŒ–`,

        es: `${modelPersona}

${timeInfo}

Funciones adicionales:
- AnÃ¡lisis de imÃ¡genes, procesamiento de documentos, conversaciÃ³n multilingÃ¼e, bÃºsqueda web, gestiÃ³n de memoria
${memoriesContext}

Reglas importantes de idioma:
- CRÃTICO: Siempre responde en el MISMO IDIOMA que la entrada del usuario
- Detecta el idioma del usuario y responde SOLO en ese idioma
- MantÃ©n un idioma consistente en toda tu respuesta

Importante:
- Responde en el idioma del usuario
- Cita fuentes web como [Fuente: nÃºmero]
- Usa informaciÃ³n recordada para personalizaciÃ³n`,

        fr: `${modelPersona}

${timeInfo}

Fonctions supplÃ©mentaires:
- Analyse d'images, traitement de documents, conversation multilingue, recherche web, gestion de mÃ©moire
${memoriesContext}

RÃ¨gles linguistiques importantes:
- CRITIQUE: RÃ©pondez toujours dans la MÃŠME LANGUE que l'entrÃ©e de l'utilisateur
- DÃ©tectez la langue de l'utilisateur et rÃ©pondez UNIQUEMENT dans cette langue
- Maintenez une langue cohÃ©rente tout au long de votre rÃ©ponse

Important:
- RÃ©pondre dans la langue de l'utilisateur
- Citer les sources web comme [Source: numÃ©ro]
- Utiliser les informations mÃ©morisÃ©es pour la personnalisation`,

        default: `${modelPersona}

${timeInfo}

Additional capabilities:
- Image analysis, document processing, multilingual conversation, web search, memory management
${memoriesContext}

CRITICAL: Always respond in the SAME LANGUAGE as the user's input. Detect their language and maintain it throughout your response.

Important:
- Respond in the user's language
- Cite web sources as [Source: number]
- Use remembered information for personalization`
      };

      return basePrompt[language as keyof typeof basePrompt] || basePrompt.default;
    }

    // Base system prompt with language detection and model persona
    let systemPrompt = getSystemPrompt(detectedLanguage, selectedModelId);
    const promptPreview = systemPrompt.substring(0, 200);
    console.log(`[System Prompt] Using prompt for language: ${detectedLanguage}`);
    console.log(`ğŸ“ [Demo Chat API] System Prompt Preview:`, promptPreview + '...\n');

    // Add memories if enabled
    if (includeMemories && userId) {
      try {
        const memoryManager = new MemoryManager(userId);
        const memoriesText = await memoryManager.formatMemoriesForPrompt();
        if (memoriesText) {
          systemPrompt += memoriesText;
        }
      } catch (error) {
        console.error('Error loading memories:', error);
      }
    }

    // Perform web search if enabled
    let searchResults = null;
    let searchContext = '';
    if (webSearchEnabled) {
      try {
        const searchClient = getBraveSearchClient();
        
        // Generate multiple search queries for better results
        const queries = searchClient.generateSearchQueries(message.content);
        console.log('[WebSearch] Generated queries:', queries);
        
        // Map detected language to search language
        function getSearchLanguage(detectedLang: string): string {
          const langMap = {
            'ko': 'ko', 'ja': 'ja', 'zh': 'zh-cn', 'ru': 'ru',
            'ar': 'ar', 'es': 'es', 'fr': 'fr', 'de': 'de', 
            'it': 'it', 'pt': 'pt', 'th': 'th', 'vi': 'vi',
            'en': 'en'
          };
          return langMap[detectedLang as keyof typeof langMap] || 'en';
        }
        
        // Perform multi-search with detected language
        const results = await searchClient.multiSearch(queries, {
          count: 10,
          lang: getSearchLanguage(detectedLanguage)
        });

        if (results.length > 0) {
          searchResults = results;
          
          // Format search results for inclusion in system prompt
          searchContext = searchClient.formatResultsForPrompt(results);
          console.log(`[WebSearch] Found ${results.length} results`);
        }
      } catch (error) {
        console.error('Web search error:', error);
      }
    }

    // Check for shopping intent and get recommendations
    let shoppingContext = '';
    if (shoppingEnabled) {
      try {
        const shoppingClient = getShoppingAPIClient();
        const shoppingIntent = shoppingClient.detectShoppingIntent(message.content);

        console.log('[Shopping] Intent detection:', shoppingIntent);

        if (shoppingIntent.hasIntent) {
          // Enhanced user profiling based on context
          const userProfile = {
            demographics: {
              lifestyle: '1ì¸ê°€êµ¬' as const, // TODO: Extract from memory
              budgetLevel: 'standard' as const,
              ageGroup: '30ëŒ€' as const // TODO: Infer from conversation
            },
            purchaseBehavior: {
              priceSensitivity: detectedMood === 'ìŠ¤íŠ¸ë ˆìŠ¤' ? 0.3 : 0.6, // Lower when stressed
              brandLoyalty: 0.5,
              varietySeeking: detectedMood === 'ìš°ìš¸' ? 0.3 : 0.7, // Comfort food when sad
              bulkBuying: isWeekend // Bulk buy on weekends
            },
            foodPreferences: {
              spicyLevel: 3 as const,
              favoriteCategories: ['ì‹í’ˆ', 'ê°„ì‹'],
              avoidCategories: [],
              dietaryRestrictions: [] // TODO: Extract from memory
            },
            contextualNeeds: {
              currentMood: detectedMood || shoppingIntent.mood,
              healthGoals: [], // TODO: Extract from memory
              upcomingEvents: isWeekend ? ['ì£¼ë§'] : [],
              seasonalPreferences: new Map([[seasonContext, []]])
            }
          };

          // Enhanced context with time, mood, and season
          const enhancedContext = {
            mood: detectedMood || shoppingIntent.mood,
            timeOfDay: timeContext,
            season: seasonContext,
            isWeekend,
            query: shoppingIntent.searchQuery || message.content
          };

          // Determine search query based on context if not explicitly provided
          let searchQuery = shoppingIntent.searchQuery;
          if (!searchQuery) {
            // Context-based query generation
            if (enhancedContext.mood === 'ìŠ¤íŠ¸ë ˆìŠ¤') {
              searchQuery = 'ì´ˆì½œë¦¿';
            } else if (enhancedContext.timeOfDay === 'ì•¼ì‹') {
              searchQuery = 'ë¼ë©´';
            } else if (enhancedContext.timeOfDay === 'ì•„ì¹¨') {
              searchQuery = 'ë¹µ';
            } else if (enhancedContext.isWeekend) {
              searchQuery = 'ê³¼ì';
            } else {
              searchQuery = 'ê°„ì‹';
            }
          }
          // Use personalized recommendations with enhanced context
          const recommendations = await shoppingClient.getPersonalizedRecommendations(
            searchQuery,
            userProfile,
            enhancedContext
          );

          if (recommendations.products.length > 0) {
            shoppingContext = shoppingClient.formatProductsForChat(
              recommendations.products,
              recommendations.reasoning
            );
            console.log('[Shopping] Found products:', recommendations.products.length);
          }
        }
      } catch (error) {
        console.error('[Shopping] Error getting recommendations:', error);
      }
    }

    // Combine system prompt with search results and shopping recommendations
    let shoppingInstructions = '';
    if (shoppingContext && detectedLanguage === 'ko') {
      // Add personalized shopping instructions for Korean users
      if (detectedMood) {
        const moodMessages: Record<string, string> = {
          'ìŠ¤íŠ¸ë ˆìŠ¤': '\ní˜ë“  í•˜ë£¨ì˜€êµ°ìš”. ë‹¬ì½¤í•œ ê°„ì‹ìœ¼ë¡œ ê¸°ë¶„ì„ í’€ì–´ë³´ì„¸ìš”!',
          'í”¼ê³¤': '\ní”¼ê³¤í•˜ì‹œë„¤ìš”. ì—ë„ˆì§€ë¥¼ ì¶©ì „í•  ìˆ˜ ìˆëŠ” ì œí’ˆë“¤ì´ì—ìš”.',
          'ìš°ìš¸': '\në§ˆìŒì´ í˜ë“œì‹ ê°€ìš”? í–‰ë³µí•œ ë§›ìœ¼ë¡œ ê¸°ë¶„ì„ ë‹¬ë˜ë³´ì„¸ìš”.',
          'ê¸°ì¨': '\nê¸°ë¶„ ì¢‹ì€ ë‚ ì´ë„¤ìš”! íŠ¹ë³„í•œ ê°„ì‹ìœ¼ë¡œ ë” í–‰ë³µí•´ì§€ì„¸ìš”!'
        };
        shoppingInstructions = moodMessages[detectedMood] || '';
      }

      if (isWeekend) {
        shoppingInstructions += '\nì£¼ë§ íŠ¹ë³„ í• ì¸ ìƒí’ˆë„ í¬í•¨í–ˆì–´ìš”!';
      }

      if (timeContext === 'ì•¼ì‹') {
        shoppingInstructions += '\nì•¼ì‹ìœ¼ë¡œ ë”± ì¢‹ì€ ìƒí’ˆë“¤ì´ì—ìš”. ë°°ì†¡ë¹„ê°€ ë¬´ë£Œì¸ ê²ƒë“¤ ìœ„ì£¼ë¡œ ê³¨ë¼ë´¤ì–´ìš”!';
      }
    }

    const fullSystemPrompt = systemPrompt +
      (searchContext ? '\n\n' + searchContext : '') +
      (shoppingContext ? '\n\nì‡¼í•‘ ì¶”ì²œ ì •ë³´ì…ë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ë˜, ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ì²´ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. íŠ¹íˆ ì´ë¯¸ì§€ ë§ˆí¬ë‹¤ìš´(![ìƒí’ˆëª…](URL))ì€ ë°˜ë“œì‹œ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤:\n' + shoppingInstructions + '\n' + shoppingContext : '');

    // Add language-specific instruction to enforce correct response language
    let userContent = message.content;
    const languageInstructions = {
      ko: "ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”. ì˜ì–´ ê¸ˆì§€.",
      ja: "å¿…ãšæ—¥æœ¬èªã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚",
      zh: "è¯·åŠ¡å¿…åªç”¨ä¸­æ–‡å›ç­”ã€‚",
      es: "Responde solo en espaÃ±ol.",
      fr: "RÃ©pondez uniquement en franÃ§ais.",
      de: "Antworten Sie nur auf Deutsch.",
      ru: "ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹Ñ‚Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.",
      it: "Rispondi solo in italiano.",
      pt: "Responda apenas em portuguÃªs.",
      ar: "Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·.",
      th: "à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™",
      vi: "Chá»‰ tráº£ lá»i báº±ng tiáº¿ng Viá»‡t."
    };

    if (languageInstructions[detectedLanguage as keyof typeof languageInstructions]) {
      userContent = `${languageInstructions[detectedLanguage as keyof typeof languageInstructions]}

${message.content}`;
    }

    const messages = [
      {
        role: 'system',
        content: fullSystemPrompt
      },
      {
        role: 'user',
        content: userContent
      }
    ];

    // Prepare the payload for Friendli AI
    const payload = {
      model: FRIENDLI_MODEL,
      messages,
      stream: true,
      temperature: detectedLanguage === 'ko' ? 0.3 : 0.8, // Lower temperature for Korean to ensure consistency
      max_tokens: 2000
    };

    // Try Friendli AI first, then fallback to xAI Grok
    let response: Response;
    let usingFallback = false;

    try {
      console.log('[AI API] Attempting Friendli AI...');
      response = await fetch(FRIENDLI_BASE_URL, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${FRIENDLI_API_KEY}`,
          'Accept': 'text/event-stream'
        },
        body: JSON.stringify(payload)
      });

      if (!response.ok) {
        throw new Error(`Friendli AI error: ${response.status}`);
      }
      console.log('[AI API] Friendli AI successful');
    } catch (friendliError) {
      console.error('[AI API] Friendli AI failed:', friendliError);
      console.log('[AI API] Falling back to xAI Grok...');

      if (!XAI_API_KEY) {
        console.error('[AI API] No xAI API key available');
        return new Response(JSON.stringify({ error: 'AI service unavailable' }), {
          status: 500,
          headers: { 'Content-Type': 'application/json' }
        });
      }

      // Prepare payload for xAI Grok
      const xaiPayload = {
        model: XAI_MODEL,
        messages: payload.messages,
        stream: true,
        temperature: payload.temperature,
        max_tokens: payload.max_tokens
      };

      try {
        response = await fetch(XAI_BASE_URL, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${XAI_API_KEY}`,
            'Accept': 'text/event-stream'
          },
          body: JSON.stringify(xaiPayload)
        });

        if (!response.ok) {
          const errorText = await response.text();
          console.error('[AI API] xAI Grok error:', errorText);
          throw new Error(`xAI error: ${response.status}`);
        }

        console.log('[AI API] xAI Grok successful');
        usingFallback = true;
      } catch (xaiError) {
        console.error('[AI API] xAI also failed:', xaiError);
        console.log('[AI API] Trying Fireworks AI as final fallback...');

        if (!FIREWORKS_API_KEY) {
          console.error('[AI API] No Fireworks API key available');
          return new Response(JSON.stringify({ error: 'All AI services unavailable' }), {
            status: 500,
            headers: { 'Content-Type': 'application/json' }
          });
        }

        // Prepare payload for Fireworks AI
        const fireworksPayload = {
          model: FIREWORKS_MODEL,
          messages: payload.messages,
          stream: true,
          temperature: payload.temperature,
          max_tokens: payload.max_tokens
        };

        try {
          response = await fetch(FIREWORKS_BASE_URL, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${FIREWORKS_API_KEY}`,
              'Accept': 'text/event-stream'
            },
            body: JSON.stringify(fireworksPayload)
          });

          if (!response.ok) {
            const errorText = await response.text();
            console.error('[AI API] Fireworks error:', errorText);
            throw new Error(`Fireworks error: ${response.status}`);
          }

          console.log('[AI API] Fireworks AI successful');
          usingFallback = true;
        } catch (fireworksError) {
          console.error('[AI API] All AI services failed:', fireworksError);

          // Fallback to mock response for testing when all AI services fail
          if (shoppingContext) {
            // If we have shopping recommendations, return them as a simple response
            const mockResponse = `data: {"choices":[{"delta":{"content":"${shoppingContext.replace(/"/g, '\\"').replace(/\n/g, '\\n')}"}}]}\n\ndata: [DONE]\n\n`;

            return new Response(mockResponse, {
              headers: {
                'Content-Type': 'text/event-stream',
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
              }
            });
          }

          return new Response(JSON.stringify({ error: 'All AI services unavailable' }), {
            status: 500,
            headers: { 'Content-Type': 'application/json' }
          });
        }
      }
    }

    // If we have search results, append citations after the stream
    if (searchResults && response.body) {
      const reader = response.body.getReader();
      const encoder = new TextEncoder();
      
      const stream = new ReadableStream({
        async start(controller) {
          // Pass through the original response
          while (true) {
            const { done, value } = await reader.read();
            
            if (done) {
              // Add search citations at the end
              const searchClient = getBraveSearchClient();
              const citations = searchClient.createSourceCitations(searchResults);
              
              if (citations) {
                const citationEvent = `data: {"choices":[{"delta":{"content":"${citations.replace(/"/g, '\\"').replace(/\n/g, '\\n')}"}}]}\n\n`;
                controller.enqueue(encoder.encode(citationEvent));
              }
              
              controller.close();
              break;
            }
            
            controller.enqueue(value);
          }
        }
      });

      return new Response(stream, {
        headers: {
          'Content-Type': 'text/event-stream',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive',
          'Access-Control-Allow-Origin': '*',
          'Access-Control-Allow-Methods': 'POST, OPTIONS',
          'Access-Control-Allow-Headers': 'Content-Type'
        },
      });
    }

    // Return the streaming response directly
    return new Response(response.body, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Methods': 'POST, OPTIONS',
        'Access-Control-Allow-Headers': 'Content-Type'
      },
    });
    
  } catch (error) {
    console.error('Enhanced Demo Chat API error:', error);
    return new Response(JSON.stringify({ error: error instanceof Error ? error.message : 'Unknown error' }), {
      status: 500,
      headers: {
        'Content-Type': 'application/json',
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Methods': 'POST, OPTIONS',
        'Access-Control-Allow-Headers': 'Content-Type'
      }
    });
  }
}

// Handle CORS preflight requests
export async function OPTIONS() {
  return new Response(null, {
    status: 204,
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type, Accept, Authorization',
      'Access-Control-Max-Age': '86400',
    }
  });
}