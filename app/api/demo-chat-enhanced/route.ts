// Enhanced Friendli AI integration with memory, web search, and shopping
import { getBraveSearchClient } from '@/lib/ai/brave-search';
import { MemoryManager } from '@/lib/ai/memory-manager';
import { getEnhancedMemoryManagerV2 } from '@/lib/ai/enhanced-memory-manager-v2';
import type { Message as MemoryMessage, UserMemory } from '@/lib/ai/types';
import { DEMO_USER_ID } from '@/lib/constants/demo-user';
import { getShoppingAPIClient } from '@/lib/api/shopping-api';
import { getVectorMemoryManager } from '@/lib/ai/vector-memory-manager';
import { getModelById } from '@/lib/ai/models-config';

// Use environment variables for Friendli AI
const FRIENDLI_API_KEY = process.env.FRIENDLI_API_KEY || '';
const FRIENDLI_BASE_URL = process.env.FRIENDLI_URL || 'https://api.friendli.ai/dedicated/v1/chat/completions';
const FRIENDLI_MODEL = process.env.FRIENDLI_MODEL || 'dep86pjolcjjnv8';

// xAI Grok as fallback
const XAI_API_KEY = process.env.XAI_API_KEY || '';
const XAI_BASE_URL = 'https://api.x.ai/v1/chat/completions';
const XAI_MODEL = 'grok-beta';

// Fireworks AI as secondary fallback
const FIREWORKS_API_KEY = process.env.FIREWORKS_API_KEY || '';
const FIREWORKS_BASE_URL = 'https://api.fireworks.ai/inference/v1/chat/completions';
const FIREWORKS_MODEL = 'accounts/fireworks/models/qwen3-235b-a22b-instruct-2507';

// Korean Standard Time and Context
function getCurrentTimeKST() {
  const now = new Date();
  const kstOffset = 9 * 60; // KST is UTC+9
  const utcTime = now.getTime() + (now.getTimezoneOffset() * 60000);
  const kstTime = new Date(utcTime + (kstOffset * 60000));
  return kstTime;
}

function getTimeContext(): string {
  const hour = getCurrentTimeKST().getHours();
  if (hour >= 5 && hour < 10) return 'ÏïÑÏπ®';
  if (hour >= 10 && hour < 14) return 'Ï†êÏã¨';
  if (hour >= 14 && hour < 18) return 'Ïò§ÌõÑ';
  if (hour >= 18 && hour < 22) return 'Ï†ÄÎÖÅ';
  return 'ÏïºÏãù';
}

function getSeasonContext(): string {
  const month = getCurrentTimeKST().getMonth() + 1;
  if (month >= 3 && month <= 5) return 'Î¥Ñ';
  if (month >= 6 && month <= 8) return 'Ïó¨Î¶Ñ';
  if (month >= 9 && month <= 11) return 'Í∞ÄÏùÑ';
  return 'Í≤®Ïö∏';
}

function getMoodFromMessage(message: string): string | undefined {
  const moods: Record<string, string[]> = {
    'Ïä§Ìä∏Î†àÏä§': ['Ïä§Ìä∏Î†àÏä§', 'ÏßúÏ¶ù', 'ÌûòÎì§', 'ÌîºÍ≥§'],
    'Ïö∞Ïö∏': ['Ïö∞Ïö∏', 'Ïä¨Ìçº', 'Ïô∏Î°úÏõå', 'Ïì∏Ïì∏'],
    'Í∏∞ÏÅ®': ['Í∏∞Îªê', 'Ï¢ãÏïÑ', 'Ïã†ÎÇò', 'ÌñâÎ≥µ'],
    'ÌîºÍ≥§': ['ÌîºÍ≥§', 'Ï°∏Î†§', 'ÏßÄÏ≥ê', 'ÎÇòÎ•∏'],
    'Í±¥Í∞ïÍ¥ÄÏã¨': ['Îã§Ïù¥Ïñ¥Ìä∏', 'Í±¥Í∞ï', 'Ïö¥Îèô', 'ÏÇ¥ÎπºÍ∏∞']
  };

  for (const [mood, keywords] of Object.entries(moods)) {
    if (keywords.some(k => message.includes(k))) {
      return mood;
    }
  }
  return undefined;
}

export async function POST(request: Request) {
  try {
    const json = await request.json();
    const {
      message,
      selectedModelId = 'jetxa-model',
      webSearchEnabled = false,
      userId = DEMO_USER_ID,
      sessionId,
      includeMemories = false,
      shoppingEnabled = true
    } = json;

    if (!message || !message.content) {
      return new Response('Message content is required', { status: 400 });
    }

    console.log('Enhanced demo chat request:', {
      message: message.content.substring(0, 100),
      selectedModelId,
      webSearchEnabled,
      includeMemories
    });

    // Get contextual information
    const timeContext = getTimeContext();
    const seasonContext = getSeasonContext();
    const detectedMood = getMoodFromMessage(message.content);
    const dayOfWeek = getCurrentTimeKST().getDay();
    const isWeekend = dayOfWeek === 0 || dayOfWeek === 6;

    // Process message with Enhanced Memory Manager V2
    const enhancedMemoryManager = getEnhancedMemoryManagerV2();

    // Load existing memories for context
    let memoriesContext = '';
    let relatedMemoriesContext = '';
    if (includeMemories) {
      try {
        const memoryManager = new MemoryManager(userId);
        const memories = await memoryManager.getAllMemories();

        if (memories.length > 0) {
          console.log(`[MemoryLoader] Found ${memories.length} memories for user ${userId}`);

          // Group memories by category for better organization
          const categorizedMemories: Record<string, string[]> = {};
          memories.forEach(memory => {
            if (!categorizedMemories[memory.category]) {
              categorizedMemories[memory.category] = [];
            }
            categorizedMemories[memory.category].push(memory.content);
          });

          // Format memories for prompt
          memoriesContext = '\n\nüìö Í∏∞ÏñµÎêú Ï†ïÎ≥¥:\n';
          for (const [category, items] of Object.entries(categorizedMemories)) {
            const categoryName = category.replace('_', ' ').toUpperCase();
            memoriesContext += `\n[${categoryName}]\n`;
            items.forEach(item => {
              memoriesContext += `‚Ä¢ ${item}\n`;
            });
          }

          console.log('[MemoryLoader] Memories loaded and formatted for context');

          // Try vector search for related memories
          try {
            const vectorManager = getVectorMemoryManager();
            relatedMemoriesContext = await vectorManager.getRelatedMemories(
              message.content,
              userId,
              3
            );
            if (relatedMemoriesContext) {
              console.log('[VectorSearch] Found related memories via semantic search');
              memoriesContext += relatedMemoriesContext;
            }
          } catch (error) {
            console.log('[VectorSearch] Vector search error:', error);
            console.log('[VectorSearch] Falling back to basic memory only');
          }
        } else {
          console.log('[MemoryLoader] No memories found for user');
        }
      } catch (error) {
        console.error('[MemoryLoader] Error loading memories:', error);
      }
    }

    // Create memory message object
    const memoryMessage: MemoryMessage = {
      role: 'user',
      content: message.content,
      timestamp: new Date(),
      sessionId: sessionId || 'demo-session'
    };

    // Process memory asynchronously (don't block the response)
    const processMemory = async () => {
      try {
        const memoryResult = await enhancedMemoryManager.processMemoryComprehensively(
          memoryMessage,
          userId,
          [], // TODO: Load existing memories from database
          [] // TODO: Load conversation history
        );

        console.log('[EnhancedMemory] Processing result:', {
          shouldSave: memoryResult.shouldSave,
          category: memoryResult.processedMemory?.category,
          importance: memoryResult.processedMemory?.importance,
          emotion: memoryResult.processedMemory?.emotionalContext?.primaryEmotion
        });

        // If memory should be saved, store it in the database
        if (memoryResult.shouldSave && memoryResult.processedMemory) {
          // Initialize MemoryManager with userId
          const memoryManager = new MemoryManager(userId);

          // Extract confidence value (default to 1.0 if not provided)
          const confidence = memoryResult.processedMemory.confidence || 1.0;

          // Save memory with correct parameters - ensure sessionId is valid UUID format
          const validSessionId = sessionId && sessionId.match(/^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i)
            ? sessionId
            : null;

          await memoryManager.saveMemory(
            memoryResult.processedMemory.category || 'general',
            memoryResult.processedMemory.content || '',
            confidence,
            validSessionId
          );

          console.log('[EnhancedMemory] Memory saved successfully with:', {
            category: memoryResult.processedMemory.category,
            content: memoryResult.processedMemory.content?.substring(0, 50) + '...' || 'N/A',
            confidence: confidence,
            sessionId: validSessionId
          });
        }
      } catch (error) {
        console.error('[EnhancedMemory] Error processing memory:', error);
      }
    };

    // Start memory processing in background
    processMemory();

    // Get current time info
    const currentTime = getCurrentTimeKST();
    const kstString = currentTime.toLocaleString('ko-KR', { 
      timeZone: 'Asia/Seoul',
      year: 'numeric',
      month: 'long',
      day: 'numeric',
      hour: '2-digit',
      minute: '2-digit',
      second: '2-digit',
      weekday: 'long'
    });
    const timeInfo = `
ÌòÑÏû¨ ÏãúÍ∞Ñ Ï†ïÎ≥¥:
- ÌïúÍµ≠ ÌëúÏ§ÄÏãú(KST): ${kstString}
`;

    // Enhanced language detection function
    function detectLanguage(text: string): string {
      // Clean text for better detection
      const cleanText = text.trim().toLowerCase();
      
      // Korean (Hangul) - highest priority for Korean characters
      if (/[„Ñ±-„Öé„Öè-„Ö£Í∞Ä-Ìû£]/.test(text)) return 'ko';
      
      // Japanese (Hiragana, Katakana, Kanji)
      if (/[\u3040-\u309F\u30A0-\u30FF]/.test(text)) return 'ja';
      
      // Chinese (CJK Unified Ideographs) - but exclude if already detected as Japanese/Korean
      if (/[\u4E00-\u9FFF]/.test(text) && !/[\u3040-\u309F\u30A0-\u30FF]/.test(text) && !/[„Ñ±-„Öé„Öè-„Ö£Í∞Ä-Ìû£]/.test(text)) return 'zh';
      
      // Russian (Cyrillic)
      if (/[\u0400-\u04FF]/.test(text)) return 'ru';
      
      // Arabic
      if (/[\u0600-\u06FF]/.test(text)) return 'ar';
      
      // Thai
      if (/[\u0E00-\u0E7F]/.test(text)) return 'th';
      
      // Vietnamese (has diacritics) - more comprehensive check
      if (/[√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒë]/.test(cleanText)) return 'vi';
      
      // Spanish detection - improved with common words and patterns
      if (/[√±]/.test(cleanText) || /\b(el|la|los|las|un|una|de|en|y|que|es|por|para|con|hola|gracias|espa√±ol)\b/.test(cleanText)) return 'es';
      
      // French detection - improved with common words
      if (/[√†√¢√§√©√®√™√´√Æ√Ø√¥√∂√π√ª√º√ø√ß]/.test(cleanText) || /\b(le|la|les|un|une|de|du|des|et|que|est|pour|avec|bonjour|merci|fran√ßais)\b/.test(cleanText)) return 'fr';
      
      // German detection - improved
      if (/[√§√∂√º√ü]/.test(cleanText) || /\b(der|die|das|und|ist|mit|f√ºr|auf|ich|sie|es|hallo|danke|deutsch)\b/.test(cleanText)) return 'de';
      
      // Italian detection - improved
      if (/\b(il|la|lo|gli|le|un|una|di|in|da|per|con|che|√®|sono|ciao|grazie|italiano)\b/.test(cleanText)) return 'it';
      
      // Portuguese detection - improved
      if (/[√£√µ]/.test(cleanText) || /\b(o|a|os|as|um|uma|de|em|para|com|que|√©|s√£o|ol√°|obrigado|portugu√™s)\b/.test(cleanText)) return 'pt';
      
      // Default to English if Latin alphabet
      if (/[a-zA-Z]/.test(text)) return 'en';
      
      // Fallback
      return 'en';
    }
    
    // Detect input language
    const detectedLanguage = detectLanguage(message.content);
    const isEnglish = detectedLanguage === 'en';
    
    // Debug: Log detected language
    console.log(`[Language Detection] Input: "${message.content.substring(0, 50)}" ‚Üí Detected: ${detectedLanguage}`);

    // Get selected model configuration
    const selectedModel = getModelById(selectedModelId);
    console.log('\nüéØ [Demo Chat API] Selected Model:', {
      id: selectedModelId,
      name: selectedModel?.name || 'Unknown',
      category: selectedModel?.category || 'Unknown',
      hasPersona: !!selectedModel?.persona,
    });

    // Generate system prompt based on detected language and selected model
    function getSystemPrompt(language: string, modelId: string): string {
      // Get model persona or use default
      const model = getModelById(modelId);
      const modelPersona = model?.persona || 'You are an advanced AI assistant.';

      const basePrompt = {
        ko: `${modelPersona}

${timeInfo}

Ï∂îÍ∞Ä Í∏∞Îä•:
- ÏóÖÎ°úÎìúÎêú Ïù¥ÎØ∏ÏßÄÎ•º Î∂ÑÏÑùÌïòÍ≥† ÏÑ§Î™ÖÌï† Ïàò ÏûàÏùå
- PDF, CSV, TXT Îì± Îã§ÏñëÌïú ÌååÏùº ÌòïÏãù Ï≤òÎ¶¨
- ÌååÏùº ÎÇ¥Ïö©ÏùÑ Í∏∞Î∞òÏúºÎ°ú ÏßàÎ¨∏Ïóê ÎãµÎ≥Ä
- Î™®Îì† Ïñ∏Ïñ¥Î°ú ÏûêÏó∞Ïä§Îü¨Ïö¥ ÎåÄÌôî
- Ïõπ Í≤ÄÏÉâÏùÑ ÌÜµÌïú ÏµúÏã† Ï†ïÎ≥¥ Ï†úÍ≥µ
- ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥ Í∏∞Ïñµ Î∞è Í∞úÏù∏ÌôîÎêú ÎåÄÌôî
${memoriesContext}

**Îß§Ïö∞ Ï§ëÏöîÌïú Ïñ∏Ïñ¥ Í∑úÏπô:**
- üö® Ï†àÎåÄÏ†ÅÏúºÎ°ú Ï§ëÏöî: Î∞òÎìúÏãú ÌïúÍµ≠Ïñ¥Î°úÎßå ÏùëÎãµÌïòÏÑ∏Ïöî
- ÏÇ¨Ïö©ÏûêÍ∞Ä ÌïúÍµ≠Ïñ¥Î°ú ÏßàÎ¨∏ÌïòÎ©¥ Î¨¥Ï°∞Í±¥ ÌïúÍµ≠Ïñ¥Î°ú ÎãµÎ≥Ä
- ÏòÅÏñ¥ ÎòêÎäî Îã§Î•∏ Ïñ∏Ïñ¥Îäî Ï†àÎåÄ ÏÇ¨Ïö©ÌïòÏßÄ ÎßàÏÑ∏Ïöî
- ÌïúÍµ≠Ïñ¥Í∞Ä ÏïÑÎãå Ïñ∏Ïñ¥Î°ú ÏùëÎãµÌïòÎäî Í≤ÉÏùÄ Í∏àÏßÄÎê©ÎãàÎã§
- Ïõπ Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä ÏòÅÏñ¥ÎùºÎèÑ ÌïúÍµ≠Ïñ¥Î°ú Î≤àÏó≠Ìï¥ÏÑú ÎãµÎ≥ÄÌïòÏÑ∏Ïöî

Ï§ëÏöî:
- ÏÇ¨Ïö©ÏûêÍ∞Ä ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌñàÎã§Î©¥, ÌååÏùº ÎÇ¥Ïö©ÏùÑ Ïù∏ÏßÄÌïòÍ≥† Í¥ÄÎ†® ÏßàÎ¨∏Ïóê ÎãµÎ≥ÄÌïòÏÑ∏Ïöî.
- Ïõπ Í≤ÄÏÉâ Í≤∞Í≥ºÎ•º ÏÇ¨Ïö©Ìï† ÎïåÎäî Î∞òÎìúÏãú [Ï∂úÏ≤ò: Î≤àÌò∏] ÌòïÏãùÏúºÎ°ú Ï∂úÏ≤òÎ•º Î™ÖÏãúÌïòÏÑ∏Ïöî.
- Í∏∞ÏñµÎêú Ï†ïÎ≥¥Î•º ÌôúÏö©ÌïòÏó¨ Îçî Í∞úÏù∏ÌôîÎêú ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌïòÏÑ∏Ïöî.
- Î™®Îì† ÏùëÎãµÏùÄ Î∞òÎìúÏãú ÌïúÍµ≠Ïñ¥Î°ú ÏûëÏÑ±ÌïòÏÑ∏Ïöî.`,

        en: `${modelPersona}

${timeInfo}

Additional Functions:
- Analyze and describe uploaded images
- Process various file formats including PDF, CSV, TXT
- Answer questions based on file content
- Natural conversation in any language
- Provide latest information through web search
- Remember user information for personalized conversations
${memoriesContext}

Important Language Rules:
- CRITICAL: Always respond in the SAME LANGUAGE as the user's input
- Detect the user's language and respond ONLY in that language
- Maintain consistent language throughout your entire response

Important:
- If user uploaded files, acknowledge the file content and answer related questions.
- When using web search results, always cite sources in [Source: number] format.
- Use remembered information to provide more personalized responses.`,

        // Add support for other major languages
        ja: `${modelPersona}

${timeInfo}

ËøΩÂä†Ê©üËÉΩ:
- ÁîªÂÉèÂàÜÊûê„ÄÅÊñáÊõ∏Âá¶ÁêÜ„ÄÅÂ§öË®ÄË™ûÂØæË©±„ÄÅ„Ç¶„Çß„ÉñÊ§úÁ¥¢„ÄÅ„É°„É¢„É™ÁÆ°ÁêÜ
${memoriesContext}

ÈáçË¶Å„Å™Ë®ÄË™û„É´„Éº„É´:
- ÈáçË¶Å: Â∏∏„Å´„É¶„Éº„Ç∂„Éº„ÅÆÂÖ•Âäõ„Å®Âêå„ÅòË®ÄË™û„ÅßÂøúÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ
- „É¶„Éº„Ç∂„Éº„ÅÆË®ÄË™û„ÇíÊ§úÂá∫„Åó„ÄÅ„Åù„ÅÆË®ÄË™û„ÅÆ„Åø„ÅßÂøúÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ
- ÂøúÁ≠îÂÖ®‰Ωì„ÇíÈÄö„Åó„Å¶‰∏ÄË≤´„Åó„ÅüË®ÄË™û„ÇíÁ∂≠ÊåÅ„Åó„Å¶„Åè„Å†„Åï„ÅÑ

ÈáçË¶Å:
- „É¶„Éº„Ç∂„Éº„ÅÆË®ÄË™û„ÅßÂøúÁ≠î„Åô„Çã
- „Ç¶„Çß„Éñ„ÇΩ„Éº„Çπ„Çí[Âá∫ÂÖ∏: Áï™Âè∑]ÂΩ¢Âºè„ÅßÂºïÁî®„Åô„Çã
- Ë®òÊÜ∂„Åï„Çå„ÅüÊÉÖÂ†±„ÇíÂÄã‰∫∫Âåñ„Å´Ê¥ªÁî®„Åô„Çã`,

        zh: `${modelPersona}

${timeInfo}

ËøΩÂä†ÂäüËÉΩ:
- ÂõæÂÉèÂàÜÊûê„ÄÅÊñáÊ°£Â§ÑÁêÜ„ÄÅÂ§öËØ≠Ë®ÄÂØπËØù„ÄÅÁΩëÁªúÊêúÁ¥¢„ÄÅËÆ∞ÂøÜÁÆ°ÁêÜ
${memoriesContext}

ÈáçË¶ÅÁöÑËØ≠Ë®ÄËßÑÂàô:
- ÂÖ≥ÈîÆ: ÂßãÁªàÁî®‰∏éÁî®Êà∑ËæìÂÖ•Áõ∏ÂêåÁöÑËØ≠Ë®ÄÂõûÂ∫î
- Ê£ÄÊµãÁî®Êà∑ÁöÑËØ≠Ë®ÄÂπ∂‰ªÖÁî®ËØ•ËØ≠Ë®ÄÂõûÂ∫î
- Âú®Êï¥‰∏™ÂõûÂ∫î‰∏≠‰øùÊåÅ‰∏ÄËá¥ÁöÑËØ≠Ë®Ä

ÈáçË¶ÅÊèêÁ§∫:
- Áî®Áî®Êà∑ÁöÑËØ≠Ë®ÄÂõûÂ∫î
- ‰ª•[Êù•Ê∫ê: Êï∞Â≠ó]Ê†ºÂºèÂºïÁî®ÁΩëÁªúÊù•Ê∫ê
- ‰ΩøÁî®ËÆ∞ÂøÜ‰ø°ÊÅØËøõË°å‰∏™ÊÄßÂåñ`,

        es: `${modelPersona}

${timeInfo}

Funciones adicionales:
- An√°lisis de im√°genes, procesamiento de documentos, conversaci√≥n multiling√ºe, b√∫squeda web, gesti√≥n de memoria
${memoriesContext}

Reglas importantes de idioma:
- CR√çTICO: Siempre responde en el MISMO IDIOMA que la entrada del usuario
- Detecta el idioma del usuario y responde SOLO en ese idioma
- Mant√©n un idioma consistente en toda tu respuesta

Importante:
- Responde en el idioma del usuario
- Cita fuentes web como [Fuente: n√∫mero]
- Usa informaci√≥n recordada para personalizaci√≥n`,

        fr: `${modelPersona}

${timeInfo}

Fonctions suppl√©mentaires:
- Analyse d'images, traitement de documents, conversation multilingue, recherche web, gestion de m√©moire
${memoriesContext}

R√®gles linguistiques importantes:
- CRITIQUE: R√©pondez toujours dans la M√äME LANGUE que l'entr√©e de l'utilisateur
- D√©tectez la langue de l'utilisateur et r√©pondez UNIQUEMENT dans cette langue
- Maintenez une langue coh√©rente tout au long de votre r√©ponse

Important:
- R√©pondre dans la langue de l'utilisateur
- Citer les sources web comme [Source: num√©ro]
- Utiliser les informations m√©moris√©es pour la personnalisation`,

        default: `${modelPersona}

${timeInfo}

Additional capabilities:
- Image analysis, document processing, multilingual conversation, web search, memory management
${memoriesContext}

CRITICAL: Always respond in the SAME LANGUAGE as the user's input. Detect their language and maintain it throughout your response.

Important:
- Respond in the user's language
- Cite web sources as [Source: number]
- Use remembered information for personalization`
      };

      return basePrompt[language as keyof typeof basePrompt] || basePrompt.default;
    }

    // Base system prompt with language detection and model persona
    let systemPrompt = getSystemPrompt(detectedLanguage, selectedModelId);
    const promptPreview = systemPrompt.substring(0, 200);
    console.log(`[System Prompt] Using prompt for language: ${detectedLanguage}`);
    console.log(`üìù [Demo Chat API] System Prompt Preview:`, promptPreview + '...\n');

    // Add memories if enabled
    if (includeMemories && userId) {
      try {
        const memoryManager = new MemoryManager(userId);
        const memoriesText = await memoryManager.formatMemoriesForPrompt();
        if (memoriesText) {
          systemPrompt += memoriesText;
        }
      } catch (error) {
        console.error('Error loading memories:', error);
      }
    }

    // Perform web search if enabled
    let searchResults = null;
    let searchContext = '';
    if (webSearchEnabled) {
      try {
        const searchClient = getBraveSearchClient();
        
        // Generate multiple search queries for better results
        const queries = searchClient.generateSearchQueries(message.content);
        console.log('[WebSearch] Generated queries:', queries);
        
        // Map detected language to search language
        function getSearchLanguage(detectedLang: string): string {
          const langMap = {
            'ko': 'ko', 'ja': 'ja', 'zh': 'zh-cn', 'ru': 'ru',
            'ar': 'ar', 'es': 'es', 'fr': 'fr', 'de': 'de', 
            'it': 'it', 'pt': 'pt', 'th': 'th', 'vi': 'vi',
            'en': 'en'
          };
          return langMap[detectedLang as keyof typeof langMap] || 'en';
        }
        
        // Perform multi-search with detected language
        const results = await searchClient.multiSearch(queries, {
          count: 10,
          lang: getSearchLanguage(detectedLanguage)
        });

        if (results.length > 0) {
          searchResults = results;
          
          // Format search results for inclusion in system prompt
          searchContext = searchClient.formatResultsForPrompt(results);
          console.log(`[WebSearch] Found ${results.length} results`);
        }
      } catch (error) {
        console.error('Web search error:', error);
      }
    }

    // Check for shopping intent and get recommendations
    let shoppingContext = '';
    if (shoppingEnabled) {
      try {
        const shoppingClient = getShoppingAPIClient();
        const shoppingIntent = shoppingClient.detectShoppingIntent(message.content);

        console.log('[Shopping] Intent detection:', shoppingIntent);

        if (shoppingIntent.hasIntent) {
          // Enhanced user profiling based on context
          const userProfile = {
            demographics: {
              lifestyle: '1Ïù∏Í∞ÄÍµ¨' as const, // TODO: Extract from memory
              budgetLevel: 'standard' as const,
              ageGroup: '30ÎåÄ' as const // TODO: Infer from conversation
            },
            purchaseBehavior: {
              priceSensitivity: detectedMood === 'Ïä§Ìä∏Î†àÏä§' ? 0.3 : 0.6, // Lower when stressed
              brandLoyalty: 0.5,
              varietySeeking: detectedMood === 'Ïö∞Ïö∏' ? 0.3 : 0.7, // Comfort food when sad
              bulkBuying: isWeekend // Bulk buy on weekends
            },
            foodPreferences: {
              spicyLevel: 3 as const,
              favoriteCategories: ['ÏãùÌíà', 'Í∞ÑÏãù'],
              avoidCategories: [],
              dietaryRestrictions: [] // TODO: Extract from memory
            },
            contextualNeeds: {
              currentMood: detectedMood || shoppingIntent.mood,
              healthGoals: [], // TODO: Extract from memory
              upcomingEvents: isWeekend ? ['Ï£ºÎßê'] : [],
              seasonalPreferences: new Map([[seasonContext, []]])
            }
          };

          // Enhanced context with time, mood, and season
          const enhancedContext = {
            mood: detectedMood || shoppingIntent.mood,
            timeOfDay: timeContext,
            season: seasonContext,
            isWeekend,
            query: shoppingIntent.searchQuery || message.content
          };

          // Determine search query based on context if not explicitly provided
          let searchQuery = shoppingIntent.searchQuery;
          if (!searchQuery) {
            // Context-based query generation
            if (enhancedContext.mood === 'Ïä§Ìä∏Î†àÏä§') {
              searchQuery = 'Ï¥àÏΩúÎ¶ø';
            } else if (enhancedContext.timeOfDay === 'ÏïºÏãù') {
              searchQuery = 'ÎùºÎ©¥';
            } else if (enhancedContext.timeOfDay === 'ÏïÑÏπ®') {
              searchQuery = 'Îπµ';
            } else if (enhancedContext.isWeekend) {
              searchQuery = 'Í≥ºÏûê';
            } else {
              searchQuery = 'Í∞ÑÏãù';
            }
          }
          // Use personalized recommendations with enhanced context
          const recommendations = await shoppingClient.getPersonalizedRecommendations(
            searchQuery,
            userProfile,
            enhancedContext
          );

          if (recommendations.products.length > 0) {
            shoppingContext = shoppingClient.formatProductsForChat(
              recommendations.products,
              recommendations.reasoning
            );
            console.log('[Shopping] Found products:', recommendations.products.length);
          }
        }
      } catch (error) {
        console.error('[Shopping] Error getting recommendations:', error);
      }
    }

    // Combine system prompt with search results and shopping recommendations
    let shoppingInstructions = '';
    if (shoppingContext && detectedLanguage === 'ko') {
      // Add personalized shopping instructions for Korean users
      if (detectedMood) {
        const moodMessages: Record<string, string> = {
          'Ïä§Ìä∏Î†àÏä§': '\nÌûòÎì† ÌïòÎ£®ÏòÄÍµ∞Ïöî. Îã¨ÏΩ§Ìïú Í∞ÑÏãùÏúºÎ°ú Í∏∞Î∂ÑÏùÑ ÌíÄÏñ¥Î≥¥ÏÑ∏Ïöî!',
          'ÌîºÍ≥§': '\nÌîºÍ≥§ÌïòÏãúÎÑ§Ïöî. ÏóêÎÑàÏßÄÎ•º Ï∂©Ï†ÑÌï† Ïàò ÏûàÎäî Ï†úÌíàÎì§Ïù¥ÏóêÏöî.',
          'Ïö∞Ïö∏': '\nÎßàÏùåÏù¥ ÌûòÎìúÏã†Í∞ÄÏöî? ÌñâÎ≥µÌïú ÎßõÏúºÎ°ú Í∏∞Î∂ÑÏùÑ Îã¨ÎûòÎ≥¥ÏÑ∏Ïöî.',
          'Í∏∞ÏÅ®': '\nÍ∏∞Î∂Ñ Ï¢ãÏùÄ ÎÇ†Ïù¥ÎÑ§Ïöî! ÌäπÎ≥ÑÌïú Í∞ÑÏãùÏúºÎ°ú Îçî ÌñâÎ≥µÌï¥ÏßÄÏÑ∏Ïöî!'
        };
        shoppingInstructions = moodMessages[detectedMood] || '';
      }

      if (isWeekend) {
        shoppingInstructions += '\nÏ£ºÎßê ÌäπÎ≥Ñ Ìï†Ïù∏ ÏÉÅÌíàÎèÑ Ìè¨Ìï®ÌñàÏñ¥Ïöî!';
      }

      if (timeContext === 'ÏïºÏãù') {
        shoppingInstructions += '\nÏïºÏãùÏúºÎ°ú Îî± Ï¢ãÏùÄ ÏÉÅÌíàÎì§Ïù¥ÏóêÏöî. Î∞∞ÏÜ°ÎπÑÍ∞Ä Î¨¥Î£åÏù∏ Í≤ÉÎì§ ÏúÑÏ£ºÎ°ú Í≥®ÎùºÎ¥§Ïñ¥Ïöî!';
      }
    }

    const fullSystemPrompt = systemPrompt +
      (searchContext ? '\n\n' + searchContext : '') +
      (shoppingContext ? '\n\nÏáºÌïë Ï∂îÏ≤ú Ï†ïÎ≥¥ÏûÖÎãàÎã§. ÏïÑÎûò ÎÇ¥Ïö©ÏùÑ Í∑∏ÎåÄÎ°ú Ï†ÑÎã¨ÌïòÎêò, ÏûêÏó∞Ïä§ÎüΩÍ≤å ÎåÄÌôîÏ≤¥Î°ú ÏùëÎãµÌï¥Ï£ºÏÑ∏Ïöî. ÌäπÌûà Ïù¥ÎØ∏ÏßÄ ÎßàÌÅ¨Îã§Ïö¥(![ÏÉÅÌíàÎ™Ö](URL))ÏùÄ Î∞òÎìúÏãú Ïú†ÏßÄÌï¥Ïïº Ìï©ÎãàÎã§:\n' + shoppingInstructions + '\n' + shoppingContext : '');

    // Add language-specific instruction to enforce correct response language
    let userContent = message.content;
    const languageInstructions = {
      ko: "Î∞òÎìúÏãú ÌïúÍµ≠Ïñ¥Î°úÎßå ÎãµÎ≥ÄÌïòÏÑ∏Ïöî. ÏòÅÏñ¥ Í∏àÏßÄ.",
      ja: "ÂøÖ„ÅöÊó•Êú¨Ë™û„ÅÆ„Åø„ÅßÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ",
      zh: "ËØ∑Âä°ÂøÖÂè™Áî®‰∏≠ÊñáÂõûÁ≠î„ÄÇ",
      es: "Responde solo en espa√±ol.",
      fr: "R√©pondez uniquement en fran√ßais.",
      de: "Antworten Sie nur auf Deutsch.",
      ru: "–û—Ç–≤–µ—á–∞–π—Ç–µ —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.",
      it: "Rispondi solo in italiano.",
      pt: "Responda apenas em portugu√™s.",
      ar: "ÿ£ÿ¨ÿ® ÿ®ÿßŸÑŸÑÿ∫ÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ŸÅŸÇÿ∑.",
      th: "‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô",
      vi: "Ch·ªâ tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát."
    };

    if (languageInstructions[detectedLanguage as keyof typeof languageInstructions]) {
      userContent = `${languageInstructions[detectedLanguage as keyof typeof languageInstructions]}

${message.content}`;
    }

    const messages = [
      {
        role: 'system',
        content: fullSystemPrompt
      },
      {
        role: 'user',
        content: userContent
      }
    ];

    // Prepare the payload for Friendli AI
    const payload = {
      model: FRIENDLI_MODEL,
      messages,
      stream: true,
      temperature: detectedLanguage === 'ko' ? 0.3 : 0.8, // Lower temperature for Korean to ensure consistency
      max_tokens: 2000
    };

    // Try Friendli AI first, then fallback to xAI Grok
    let response: Response;
    let usingFallback = false;

    try {
      console.log('[AI API] Attempting Friendli AI...');
      response = await fetch(FRIENDLI_BASE_URL, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${FRIENDLI_API_KEY}`,
          'Accept': 'text/event-stream'
        },
        body: JSON.stringify(payload)
      });

      if (!response.ok) {
        throw new Error(`Friendli AI error: ${response.status}`);
      }
      console.log('[AI API] Friendli AI successful');
    } catch (friendliError) {
      console.error('[AI API] Friendli AI failed:', friendliError);
      console.log('[AI API] Falling back to xAI Grok...');

      if (!XAI_API_KEY) {
        console.error('[AI API] No xAI API key available');
        return new Response(JSON.stringify({ error: 'AI service unavailable' }), {
          status: 500,
          headers: { 'Content-Type': 'application/json' }
        });
      }

      // Prepare payload for xAI Grok
      const xaiPayload = {
        model: XAI_MODEL,
        messages: payload.messages,
        stream: true,
        temperature: payload.temperature,
        max_tokens: payload.max_tokens
      };

      try {
        response = await fetch(XAI_BASE_URL, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${XAI_API_KEY}`,
            'Accept': 'text/event-stream'
          },
          body: JSON.stringify(xaiPayload)
        });

        if (!response.ok) {
          const errorText = await response.text();
          console.error('[AI API] xAI Grok error:', errorText);
          throw new Error(`xAI error: ${response.status}`);
        }

        console.log('[AI API] xAI Grok successful');
        usingFallback = true;
      } catch (xaiError) {
        console.error('[AI API] xAI also failed:', xaiError);
        console.log('[AI API] Trying Fireworks AI as final fallback...');

        if (!FIREWORKS_API_KEY) {
          console.error('[AI API] No Fireworks API key available');
          return new Response(JSON.stringify({ error: 'All AI services unavailable' }), {
            status: 500,
            headers: { 'Content-Type': 'application/json' }
          });
        }

        // Prepare payload for Fireworks AI
        const fireworksPayload = {
          model: FIREWORKS_MODEL,
          messages: payload.messages,
          stream: true,
          temperature: payload.temperature,
          max_tokens: payload.max_tokens
        };

        try {
          response = await fetch(FIREWORKS_BASE_URL, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${FIREWORKS_API_KEY}`,
              'Accept': 'text/event-stream'
            },
            body: JSON.stringify(fireworksPayload)
          });

          if (!response.ok) {
            const errorText = await response.text();
            console.error('[AI API] Fireworks error:', errorText);
            throw new Error(`Fireworks error: ${response.status}`);
          }

          console.log('[AI API] Fireworks AI successful');
          usingFallback = true;
        } catch (fireworksError) {
          console.error('[AI API] All AI services failed:', fireworksError);

          // Fallback to mock response for testing when all AI services fail
          if (shoppingContext) {
            // If we have shopping recommendations, return them as a simple response
            const mockResponse = `data: {"choices":[{"delta":{"content":"${shoppingContext.replace(/"/g, '\\"').replace(/\n/g, '\\n')}"}}]}\n\ndata: [DONE]\n\n`;

            return new Response(mockResponse, {
              headers: {
                'Content-Type': 'text/event-stream',
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
              }
            });
          }

          return new Response(JSON.stringify({ error: 'All AI services unavailable' }), {
            status: 500,
            headers: { 'Content-Type': 'application/json' }
          });
        }
      }
    }

    // If we have search results, append citations after the stream
    if (searchResults && response.body) {
      const reader = response.body.getReader();
      const encoder = new TextEncoder();
      
      const stream = new ReadableStream({
        async start(controller) {
          // Pass through the original response
          while (true) {
            const { done, value } = await reader.read();
            
            if (done) {
              // Add search citations at the end
              const searchClient = getBraveSearchClient();
              const citations = searchClient.createSourceCitations(searchResults);
              
              if (citations) {
                const citationEvent = `data: {"choices":[{"delta":{"content":"${citations.replace(/"/g, '\\"').replace(/\n/g, '\\n')}"}}]}\n\n`;
                controller.enqueue(encoder.encode(citationEvent));
              }
              
              controller.close();
              break;
            }
            
            controller.enqueue(value);
          }
        }
      });

      return new Response(stream, {
        headers: {
          'Content-Type': 'text/event-stream',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive',
          'Access-Control-Allow-Origin': '*',
          'Access-Control-Allow-Methods': 'POST, OPTIONS',
          'Access-Control-Allow-Headers': 'Content-Type'
        },
      });
    }

    // Return the streaming response directly
    return new Response(response.body, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Methods': 'POST, OPTIONS',
        'Access-Control-Allow-Headers': 'Content-Type'
      },
    });
    
  } catch (error) {
    console.error('Enhanced Demo Chat API error:', error);
    return new Response(JSON.stringify({ error: error instanceof Error ? error.message : 'Unknown error' }), {
      status: 500,
      headers: {
        'Content-Type': 'application/json',
        'Access-Control-Allow-Origin': '*',
        'Access-Control-Allow-Methods': 'POST, OPTIONS',
        'Access-Control-Allow-Headers': 'Content-Type'
      }
    });
  }
}

// Handle CORS preflight requests
export async function OPTIONS() {
  return new Response(null, {
    status: 204,
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type, Accept, Authorization',
      'Access-Control-Max-Age': '86400',
    }
  });
}