import { NextRequest, NextResponse } from 'next/server';
import { auth } from '@/app/(auth)/auth';
import { put } from '@vercel/blob';
import Papa from 'papaparse';

// PDF processing with multiple fallback strategies
async function extractPdfText(buffer: Buffer): Promise<string> {
  // Strategy 1: Try pdfjs-dist (more reliable)
  try {
    const pdfjsLib = await import('pdfjs-dist');
    
    // Set worker source for pdfjs-dist
    pdfjsLib.GlobalWorkerOptions.workerSrc = `//cdnjs.cloudflare.com/ajax/libs/pdf.js/${pdfjsLib.version}/pdf.worker.min.js`;
    
    const loadingTask = pdfjsLib.getDocument({ data: buffer });
    const pdf = await loadingTask.promise;
    
    let fullText = '';
    for (let i = 1; i <= pdf.numPages; i++) {
      const page = await pdf.getPage(i);
      const textContent = await page.getTextContent();
      const pageText = textContent.items
        .map((item: any) => item.str)
        .join(' ');
      fullText += pageText + '\n';
    }
    
    return fullText.trim();
  } catch (error) {
    console.log('pdfjs-dist failed, trying pdf-parse:', error instanceof Error ? error.message : 'Unknown error');
    
    // Strategy 2: Try pdf-parse as fallback
    try {
      const pdfParse = await import('pdf-parse');
      const data = await pdfParse.default(buffer);
      return data.text || '';
    } catch (parseError) {
      console.log('pdf-parse also failed, using basic extraction:', parseError instanceof Error ? parseError.message : 'Unknown error');
      
      // Strategy 3: Basic text extraction from PDF buffer
      try {
        const text = buffer.toString('utf8');
        // Extract readable text patterns from PDF
        const textMatches = text.match(/[\x20-\x7E\uAC00-\uD7A3]{10,}/g) || [];
        const extractedText = textMatches
          .filter(match => !match.includes('obj') && !match.includes('endobj'))
          .join(' ')
          .slice(0, 10000);
        
        if (extractedText.length > 100) {
          return extractedText;
        }
      } catch (e) {
        console.error('Basic text extraction failed:', e);
      }
    }
  }
  
  return '';
}

export async function POST(request: NextRequest) {
  try {
    // Skip auth for demo mode
    const session = await auth();
    const isDemoMode = request.headers.get('x-demo-mode') === 'true';
    
    if (!isDemoMode && !session?.user) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    const formData = await request.formData();
    const file = formData.get('file') as File;
    const sessionId = formData.get('sessionId') as string;

    if (!file) {
      return NextResponse.json({ error: 'No file provided' }, { status: 400 });
    }

    // Get file extension
    const fileExt = file.name.split('.').pop()?.toLowerCase();
    let processedContent = '';

    // Read file content
    const bytes = await file.arrayBuffer();
    const buffer = Buffer.from(bytes);

    // Process based on file type
    switch (fileExt) {
      case 'pdf':
        // Enhanced PDF processing with fallback
        try {
          const extractedText = await extractPdfText(buffer);
          
          processedContent = `ğŸ“„ PDF íŒŒì¼ ë¶„ì„\n\n`;
          processedContent += `**íŒŒì¼ ì •ë³´**:\n`;
          processedContent += `- íŒŒì¼ëª…: ${file.name}\n`;
          processedContent += `- í¬ê¸°: ${(file.size / 1024).toFixed(2)} KB\n\n`;
          
          if (extractedText && extractedText.length > 0) {
            processedContent += `**í…ìŠ¤íŠ¸ ë‚´ìš©**:\n`;
            
            // Clean up text
            let cleanedText = extractedText.replace(/\s+/g, ' ').trim();
            
            // Limit text length for very large PDFs
            if (cleanedText.length > 10000) {
              processedContent += cleanedText.substring(0, 10000);
              processedContent += `\n\n... (ì „ì²´ ${cleanedText.length}ì ì¤‘ ì¼ë¶€ë§Œ í‘œì‹œ)\n`;
              processedContent += `\n**ìš”ì•½**: PDF ë¬¸ì„œê°€ ë§¤ìš° í¬ë¯€ë¡œ ì²˜ìŒ 10,000ìë§Œ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.`;
            } else {
              processedContent += cleanedText;
            }
          } else {
            processedContent += `âš ï¸ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨\n\n`;
            processedContent += `ì´ PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n`;
            processedContent += `ê°€ëŠ¥í•œ ì›ì¸:\n`;
            processedContent += `- ìŠ¤ìº”ëœ ì´ë¯¸ì§€ PDF\n`;
            processedContent += `- ì•”í˜¸í™”ëœ PDF\n`;
            processedContent += `- íŠ¹ìˆ˜ ì¸ì½”ë”© ì‚¬ìš©\n\n`;
            processedContent += `í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ë³€í™˜ í›„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.`;
          }
        } catch (error) {
          console.error('PDF processing error:', error);
          // Fallback to basic info if pdf-parse fails
          processedContent = `[PDF File: ${file.name}]\nSize: ${(file.size / 1024).toFixed(2)} KB\n`;
          processedContent += `PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`;
        }
        break;

      case 'csv':
        // Enhanced CSV processing from AGI Space
        try {
          const text = buffer.toString('utf-8');
          const result: any = Papa.parse(text, {
            header: true,
            skipEmptyLines: true,
            dynamicTyping: true
          });
          
          processedContent = `CSV ë°ì´í„° ë¶„ì„:\n`;
          processedContent += `ì´ ${result.data?.length || 0}ê°œì˜ í–‰\n`;
          
          if (result.meta?.fields) {
            processedContent += `í—¤ë”: ${result.meta.fields.join(', ')}\n\n`;
          }
          
          // Include first 10 rows with better formatting
          const preview = result.data.slice(0, 10);
          processedContent += `ì²˜ìŒ 10ê°œ í–‰ ë¯¸ë¦¬ë³´ê¸°:\n`;
          preview.forEach((row: any, index: number) => {
            processedContent += `í–‰ ${index + 1}: ${JSON.stringify(row)}\n`;
          });
          
          if (result.data.length > 10) {
            processedContent += `\n... ê·¸ ì™¸ ${result.data.length - 10}ê°œ í–‰ ë” ìˆìŒ\n`;
          }
          
          // Add data summary
          if (result.meta.fields && result.data.length > 0) {
            processedContent += `\në°ì´í„° ìš”ì•½:\n`;
            processedContent += `- ì´ ì—´ ìˆ˜: ${result.meta.fields.length}\n`;
            processedContent += `- ì´ í–‰ ìˆ˜: ${result.data.length}\n`;
          }
        } catch (error) {
          console.error('CSV processing error:', error);
          processedContent = 'CSV íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
        }
        break;

      case 'txt':
      case 'md':
      case 'log':
        // Enhanced text file processing with encoding detection
        try {
          // Try UTF-8 first, then fallback to other encodings
          let textContent = '';
          try {
            textContent = buffer.toString('utf-8');
          } catch {
            // Try other common encodings
            try {
              textContent = buffer.toString('utf-16le');
            } catch {
              textContent = buffer.toString('latin1');
            }
          }
          
          processedContent = textContent;
          
          // Add file statistics
          const lines = processedContent.split('\n');
          const words = processedContent.split(/\s+/).length;
          const chars = processedContent.length;
          
          // Limit to first 10000 characters for large files
          if (processedContent.length > 10000) {
            processedContent = processedContent.substring(0, 10000) + '\n\n...(ë‚´ìš©ì´ ì˜ë¦¼)';
            processedContent += `\n\níŒŒì¼ í†µê³„:\n`;
            processedContent += `- ì´ ì¤„ ìˆ˜: ${lines.length}\n`;
            processedContent += `- ì´ ë‹¨ì–´ ìˆ˜: ${words}\n`;
            processedContent += `- ì´ ë¬¸ì ìˆ˜: ${chars}\n`;
          }
        } catch (error) {
          console.error('Text processing error:', error);
          processedContent = 'í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
        }
        break;

      case 'jpg':
      case 'jpeg':
      case 'png':
      case 'gif':
      case 'webp':
      case 'bmp':
      case 'svg':
        // Process image file
        try {
          const base64 = buffer.toString('base64');
          const mimeType = `image/${fileExt === 'jpg' ? 'jpeg' : fileExt}`;
          
          // Create a description for AI to understand
          processedContent = `[ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œë¨]
íŒŒì¼ëª…: ${file.name}
í¬ê¸°: ${(file.size / 1024).toFixed(2)} KB
í˜•ì‹: ${mimeType}
ì„¤ëª…: ì‚¬ìš©ìê°€ ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ë‚´ìš©ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•  ì¤€ë¹„ë¥¼ í•˜ì„¸ìš”.
ì°¸ê³ : ì´ ì´ë¯¸ì§€ëŠ” base64ë¡œ ì¸ì½”ë”©ë˜ì–´ ìˆìœ¼ë©°, ì‹œê°ì  ë¶„ì„ì´ í•„ìš”í•œ ê²½ìš° í•´ë‹¹ ë‚´ìš©ì„ ì„¤ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.`;
          
        } catch (error) {
          console.error('Image processing error:', error);
          processedContent = 'ì´ë¯¸ì§€ íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
        }
        break;

      default:
        return NextResponse.json(
          { error: 'ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (ì§€ì› í˜•ì‹: PDF, CSV, TXT, JPG, PNG, GIF, WEBP, BMP, SVG)' },
          { status: 400 }
        );
    }

    // For demo mode, skip blob storage
    if (isDemoMode) {
      return NextResponse.json({
        fileId: `demo-${Date.now()}`,
        filename: file.name,
        fileType: fileExt,
        processedContent,
        url: '#', // No actual URL in demo mode
        status: 'success'
      });
    }

    // Store file metadata and processed content in blob storage (production only)
    const blob = await put(
      `uploads/${sessionId}/${file.name}`,
      buffer,
      { access: 'public' }
    );

    return NextResponse.json({
      fileId: blob.pathname,
      filename: file.name,
      fileType: fileExt,
      processedContent,
      url: blob.url,
      status: 'success'
    });

  } catch (error) {
    console.error('File upload error:', error);
    return NextResponse.json(
      { error: 'Failed to upload file' },
      { status: 500 }
    );
  }
}

export async function DELETE(request: NextRequest) {
  try {
    // Skip auth for demo mode
    const session = await auth();
    const isDemoMode = request.headers.get('x-demo-mode') === 'true';
    
    if (!isDemoMode && !session?.user) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
    }

    const { searchParams } = new URL(request.url);
    const fileId = searchParams.get('fileId');

    if (!fileId) {
      return NextResponse.json({ error: 'File ID required' }, { status: 400 });
    }

    // In production, implement actual blob deletion
    // For now, just return success
    return NextResponse.json({ status: 'ok' });

  } catch (error) {
    console.error('File deletion error:', error);
    return NextResponse.json(
      { error: 'Failed to delete file' },
      { status: 500 }
    );
  }
}